{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Generate adversarial examples in the context of the zero-knowledge threat model\n",
    "\n",
    "## Threat model in deep learning: background and definitions\n",
    "We focus on deep learning systems that are trained in a supervised setting. This modality of deep neural network (DNN) models unseen samples to a predefined set of outputs, using a function obtained from training with labeled data. Here, we use a machine learning classifier, defined by a function $f(\\cdot)$, that receives an input $x$ and output a class probability vector $y$ of all possible classes.  \n",
    "\n",
    "### Adversarial goals  \n",
    "The adversary of a deep learning system seeks to provide a modified input $x'$, called an adversarial example, that results in an incorrect output classification (JSMA paper). This form of adversarial sample has the goal of generating inputs that are still correctly classified by humans and classifiers other than the targeted DNN. Adversarial attacks can also be distinguished by how they seek to impact the DNN output integrity: a) reduce output confidence classification; b) modify the output classification to any class other the true class; c) generate an $x'$  that forces the output classification into a specific target class; and d) modify an $x$ so that the resulting $x'$ forces the output classification into a specific target class. The first two goals are referred to as *untargeted* attacks, whereas the last two are referred to as *targeted* attacks.\n",
    "\n",
    "### Defense\n",
    "A *defense* has the goal of obtaining a correct prediction even when an adversarial example is the input: $argmax(f(x))=argmax(f(x'))=y$. In the Athena framework, the defense mechanism is a combination of several diverse weak defenses. Within the context of this assignment, however, the target of the attacks will be the *undefended model* $f$ that is trained on the original dataset $D$. Additionally, the performance of another state-of-the-art defense called *Projected Gradient Decent Adversarial Training* (PGD-ADT) was compared to the undefended model and to the vanilla Athena ensemble. The PGD-ADT approach is to train networks on both the inputs $x$ and on PGD adversaries (described below).\n",
    "\n",
    "## Adversarial attacks: description and experimental settings\n",
    "We generated adversarial examples using three different attack methods. All three methods are *gradient-based attacks*. In the case of image recognition such as this one, this means that they develop a perturbation vector for the input image by 1) holding constant the model weights and treating the input as variable, and 2) obtaining a gradient correspondent to each pixel. This jointly minimizes the perturbation and maximizes the probability of \"fooling\" the classifier (i.e., the probability of the input being misclassified).\n",
    "\n",
    "For each method, we created several variants. These variants were obtained by tuning the attack parameters of each, which are described below.\n",
    "\n",
    "#### Attack 1: Fast Gradient Sign Method (FGSM; Goodfellow, Shlens, & Szegedy, 2015)\n",
    "This method processes adversarial examples as follows:\n",
    "\n",
    "$$ x' = x + \\epsilon \\cdot sign(\\nabla_xJ(x,y)) $$\n",
    "\n",
    "where $x'$ is the adversarial image, $J$ is the cost (loss) function of the target model $f$, $\\nabla_x$ is the gradient with respect to the input $x$ (original image) with corresponding correct output $y$ (original label), and $\\epsilon$ is the magnitude of the perturbation (the change made to the pixels).\n",
    "\n",
    "Note that the $\\epsilon$ parameter is a vector multiplier that ensures the perturbation is small - just large enough to provoke misclassification. We chose values of $\\epsilon$ in the range of 0.1 to 1 in increments of 0.1 ($\\epsilon$ = 0.1, 0.2, ..., 1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attack 2: Jacobian-based Saliency Map Attack (JSMA; Papernot, McDaniel, Jha, Fredrikson, Celik, & Swami, 2016)\n",
    "This method make changes to the input through the use of the *forward derivative*: the gradient of loss with each class labels with respect to all components of the input. In other words, the forward derivative is the Jacobian of the function learned by the DNN. It is used to build *adversarial saliency maps* to determine which input features (e.g., what parts of the image) should be disturbed to maximize classification error. Note that this can be done by either *increasing* or *decreasing* input features (e.g., pixel intensity).\n",
    "The formulation of the saliency map where we increase high-saliency pixels $x_{(i)}$ is\n",
    "\n",
    "\n",
    "$$\n",
    "S(x_{(i)},c) = \\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        0\\, \\text{if}\\, \\frac{\\partial f(x)_{(c)}}{\\partial x_{(i)}}\\, <\\, 0\\, \\text{or}\\, \\displaystyle\\sum_{c'\\neq c} \\frac{\\partial f(x)_{(c')}}{\\partial x_{(i)}}\\ >\\ 0 \\\\\n",
    "        -\\frac{\\partial f(x)_{(c)}}{\\partial x_(i)}\\ \\cdot\\ \\displaystyle\\sum_{c'\\neq c} \\frac{\\partial f(x)_{(c')}}{\\partial x_{(i)}}\\, \\text{otherwise.}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "This approach differs from the FGSM because it reduces the number of perturbations (i.e, the number of pixels it disturbs). We do not report results for this method because after several runs with extreme parameters, none of the results were meaningfully different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attack 3: Projected Gradient Descent (PGD; Madry, Makelov, Schmidt, Tsipras, & Vladu, 2019)\n",
    "This is an iterative approach that gradually increases the magnitude of the perturbation until the input is misclassified. Like other methods, it aims to minimize the following worst case loss function over all possible perturbations:\n",
    "\n",
    "$$\\rho(\\theta)=E_{(x,y)\\sim D}\\, \\bigg[ \\max\\limits_{\\delta\\, \\in\\, S}L(\\theta, x + \\delta,y) \\bigg]$$\n",
    "\n",
    "The FGSM described previously approaches is an attack for an $l_\\inf$-bounded adversary and generates adversarial examples as seen above. Another adversarial approach is a multi-step variant, which is the *projected gradient descent* (PGD) on the negative loss function\n",
    "\n",
    "$$ x^{t+1} = \\prod_{x+S}(x^t\\ +\\ \\alpha sign(\\nabla_x L(\\theta,x,y))) $$\n",
    "\n",
    "For the PGD, we generated attacks in two ways:\n",
    "1. Manipulating the size of the perturbation, $\\epsilon$, from 0.1 to 1 in increments of 0.1 with fixed maximum iteration of 10.\n",
    "2. Manipulating the number of maximum iterations from 10 to 30 by increments of 2 (10,12,14,...,30) with a fixed $\\epsilon$ of 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of results: error rate\n",
    "Results in terms of error rate by attack method are plotted below. The defenses are coded by color: yellow is the undefended model, green is the Athena ensemble of weak defenses, and blue is the baseline defense model, PGD-ADT. \n",
    "\n",
    "The top plot shows the performance of each defense against FGSM adversarial attacks. The undefended model starts ($\\epsilon$ = .1) with a 25% error rate and reaches the peak error rate of 92% at $\\epsilon$ = 0.4. The Athena and PGD-ADT defenses have essentially equal error rates for $\\epsilon$ = 0.1 and 0.2; at $\\epsilon$ = 0.3, however, Athena has 67% error rate while PGD-DT has an error rate of 21%. At $\\epsilon$ = 0.5 and upwards, all defenses are essentially equivalent with error rates around 90%.\n",
    "\n",
    "The middle plot shows the performance of each defense against PGD attacks with changing attack intensities, similar as the above. The undefended model has error rate of 65% at $\\epsilon$ = 0.1 and sharply reaches 99% at $\\epsilon$ = 0.2. Athena and PGD-ADT perform more closely in these scenarios, with their largest difference at $\\epsilon$ = 0.4: 23%. Athena and PGD-ADT are equivalent again at $\\epsilon$ = 0.6, with an error rate of 88%. For stronger attacks ($\\epsilon$ = 0.8 and above), Athena is the defense with smallest error rate, and is 7% more accurate than the other methods.\n",
    "\n",
    "The last plot demonstrates the change in error rate as the number of iterations is manipulated in PGD attacks with $\\epsilon$ = 0.3. The minimum error rate for Athena is 29% at 10 iterations and the maximum error rate is 59% at 30 iterations. For PGD-ADT, the minimum error rate is 18% and the maximum is 33%. Note that the minimum difference between the two methods is 11%, at 10 iterations, and the maximum difference is 26%, at 30 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File results/dataOut_task1.csv does not exist: 'results/dataOut_task1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-945bd489b5da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/dataOut_task1.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'UM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ensemble'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File results/dataOut_task1.csv does not exist: 'results/dataOut_task1.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "path = \"Data/dataOut_task1.csv\"\n",
    "\n",
    "df = pd.read_csv(path, header = None, index_col = None, parse_dates =  True)\n",
    "df.columns = ['num','ae','UM','BL','Ensemble']\n",
    "df = df.drop([0])\n",
    "#eps fgsm['nes'].iloc[x]= \"epsof\"\n",
    "\n",
    "\n",
    "fgsm = df.iloc[21::]\n",
    "i = 0\n",
    "temp = []\n",
    "for x in fgsm['ae']:\n",
    "    temp.append(float(x.split('f')[2].replace(',',\"\")))\n",
    "    i+=0\n",
    "fgsm['nes']=temp\n",
    "\n",
    "pgdesp = df.iloc[0:10] \n",
    "\n",
    "i = 0\n",
    "temp = []\n",
    "for x in pgdesp['ae']:\n",
    "    temp.append(float(x.split('f')[1].replace(',',\"\")))\n",
    "    i+=0\n",
    "pgdesp['nes']=temp\n",
    "\n",
    "pgditer =df.iloc[11:21] \n",
    "\n",
    "i = 0\n",
    "temp = []\n",
    "for x in pgditer['ae']:\n",
    "    temp.append(float(x.split('r')[1].replace(',',\"\")))\n",
    "    i+=0\n",
    "pgditer['nes']=temp\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.plot(fgsm['nes'],np.array(fgsm['BL'],dtype=float))\n",
    "ax1.plot(fgsm['nes'],np.array(fgsm['UM'],dtype=float))\n",
    "ax1.plot(fgsm['nes'],np.array(fgsm['Ensemble'],dtype=float)) \n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel(\"Error Rate\")\n",
    "ax1.set_xlabel('FGSM, Changing Epsilon Value')\n",
    "\n",
    "\n",
    "ax2.plot(pgdesp['nes'],np.array(pgdesp['BL'],dtype=float))\n",
    "ax2.plot(pgdesp['nes'],np.array(pgdesp['UM'],dtype=float))\n",
    "ax2.plot(pgdesp['nes'],np.array(pgdesp['Ensemble'],dtype=float)) \n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_ylabel('Error Rate')\n",
    "ax2.set_xlabel('PGD, Changing Epsilon Value, Max Iteration set to 10')\n",
    "\n",
    "\n",
    "ax3.plot(pgditer['nes'],np.array(pgditer['BL'],dtype=float))\n",
    "ax3.plot(pgditer['nes'],np.array(pgditer['UM'],dtype=float))\n",
    "ax3.plot(pgditer['nes'],np.array(pgditer['Ensemble'],dtype=float)) \n",
    "ax3.set_ylim(0,1)\n",
    "ax3.set_ylabel('Error Rate')\n",
    "ax3.set_xlabel('PGD, Changing Max Iteration Value, Epsilons set to 0.3')\n",
    "\n",
    "\n",
    "#plt.xlim(dates.iloc[1],dates.iloc[-1])\n",
    "#ax1.set_ylim(0,1)\n",
    "#ax1.axhline(color='r')\n",
    "#ax1.set_title(\"Correct Guess\")\n",
    "#ax1.set_ylabel('Velocity (m/yr)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Goodfellow, I.J., Shlens, J., & Szegedy, C. (2015). Explaining and Harnessing Adversarial Examples. CoRR, abs/1412.6572.\n",
    "\n",
    "Madry, A., Makelov, A., Schmidt, L., Tsipras, D., & Vladu, A. (2018). Towards Deep Learning Models Resistant to Adversarial Attacks. ArXiv, abs/1706.06083.\n",
    "\n",
    "Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.Y., & Swami, A. (2016). The Limitations of Deep Learning in Adversarial Settings. 2016 IEEE European Symposium on Security and Privacy (EuroS&P), 372-387."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
